This project is designed as a compact library of deep learning functions, primarily intended for educational use. Its primary objective is to facilitate a deep understanding of the core components of neural networks through hands-on implementation. The aim is to strike a balance between simplicity for ease of comprehension and sufficient complexity to avoid oversimplification - in other words, neither purely demonstrational, simplified implementation nor production-grade level software.

I don't have a rigid definition for the project; the immediate goal is to develop the necessary components for a basic image classification network. Below is a detailed to-do list that outlines the current focus areas:

 - [ ] Implement the foundational data structure
 - [ ] Create a reverse-mode automatic differentiation engine to obtain a decoupled backpropagation module
 - [ ] Assemble a rudimentary neural network manually from these components, serving as a proof of concept
 - [ ] Expand the library to include essential elements such as optimizers and loss functions
 - [ ] Design an API that allows for a more abstract and general construction of neural networks
 - [ ] Implement either a binary classifier or a multi-class MNIST classifier straight away